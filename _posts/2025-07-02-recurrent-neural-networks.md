---
layout: post
title: "Recurrent Neural Networks"
author: "David Weinflash"
categories: journal
tags: [documentation,sample]
image: RNN_Results.png
---

This project focuses on the performance of recurrent neural networks in the context of image 
generation and text classification. Specifically, multiple recurrent neural networks are trained 
in order to classify movie reviews from the [Internet Movie Database](https://www.imdb.com/)
and generate images from the [MNIST database](http://yann.lecun.com/exdb/mnist/). Models are 
evaluated in light of training and test data performance and also via manual verification methods.

## Goals

* Analyze the performance of two recurrent neural networks:

  * SimpleRNN
  * PixelRNN

* Train recurrent neural networks to perform different tasks:

  * **SimpleRNN** - Classify movie reviews as either positive or negative.
  * **PixelRNN** - Generate images of handwritten digits.

## Takeaways

* LSTM layers useful:

  * PixelRNN model learned the conditional probabilities of each pixel through a series of LSTM layers.
    
  * Allowed the model to increase its depth while maintaining a relatively high level of accuracy.

* RNN model may be too simplistic to be of real use, as it was ultimatley incapable of maintaining and learning long-term dependencies.

  * SimpleRNN model achieved a maximum validation accuracy of only 83.6%.
  
  * Estimated 50% of all images generated by PixelRNN are illegible.

## Documents

* [Presentation](/assets/pdf/RNN_Report.pdf)
* [Code](https://github.com/dweinflash/RNN)
